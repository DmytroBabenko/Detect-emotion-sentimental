{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import rnn\n",
    "from ast import literal_eval\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/odesa_reviews_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>bestRating</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['Ідеально', 'для', 'ділової', 'поїздки']</td>\n",
       "      <td>['Ідеально', 'для', 'ділової', 'поїздки', 'Гос...</td>\n",
       "      <td>['Nan']</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['Затишний', 'чистий', 'номер', 'з', 'усіма', ...</td>\n",
       "      <td>['Затишний', 'чистий', 'номер', 'з', 'усіма', ...</td>\n",
       "      <td>['При', 'бронюванні', 'вказала', 'час', 'прибу...</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['Все', 'сподобалося', 'Рекомендую']</td>\n",
       "      <td>['Чисто', 'тихо', 'комфортно', 'Зустрів', 'і',...</td>\n",
       "      <td>['На', 'барі', 'кава', 'тільки', '3', 'в', '1'...</td>\n",
       "      <td>9.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['Зручне', 'розташування', 'чудовий', 'вигляд'...</td>\n",
       "      <td>['Зручне', 'розташування', 'чудовий', 'вигляд'...</td>\n",
       "      <td>['Nan']</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['Все', 'чудово', '9,9', 'балів']</td>\n",
       "      <td>['Нові', 'апартаменти', 'на', 'останньому', 'п...</td>\n",
       "      <td>['Немає', 'терміналу', 'для', 'оплати', 'креди...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0          ['Ідеально', 'для', 'ділової', 'поїздки']   \n",
       "1           1  ['Затишний', 'чистий', 'номер', 'з', 'усіма', ...   \n",
       "2           2               ['Все', 'сподобалося', 'Рекомендую']   \n",
       "3           3  ['Зручне', 'розташування', 'чудовий', 'вигляд'...   \n",
       "4           4                  ['Все', 'чудово', '9,9', 'балів']   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  ['Ідеально', 'для', 'ділової', 'поїздки', 'Гос...   \n",
       "1  ['Затишний', 'чистий', 'номер', 'з', 'усіма', ...   \n",
       "2  ['Чисто', 'тихо', 'комфортно', 'Зустрів', 'і',...   \n",
       "3  ['Зручне', 'розташування', 'чудовий', 'вигляд'...   \n",
       "4  ['Нові', 'апартаменти', 'на', 'останньому', 'п...   \n",
       "\n",
       "                                                 neg  ratingValue  bestRating  \\\n",
       "0                                            ['Nan']         10.0        10.0   \n",
       "1  ['При', 'бронюванні', 'вказала', 'час', 'прибу...          9.2        10.0   \n",
       "2  ['На', 'барі', 'кава', 'тільки', '3', 'в', '1'...          9.6        10.0   \n",
       "3                                            ['Nan']         10.0        10.0   \n",
       "4  ['Немає', 'терміналу', 'для', 'оплати', 'креди...         10.0        10.0   \n",
       "\n",
       "   rate  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_file = \"./embeddings/ubercorpus.cased.tokenized.word2vec.300d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(embeddings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word2idx_and_embeddings(word2vec):\n",
    "    word_embeddings = np.zeros((len(word2vec.vocab), word2vec.vector_size))\n",
    "    word2idx = {}\n",
    "    for word in word2vec.vocab:\n",
    "        idx = len(word2idx)\n",
    "        word2idx[word] = idx\n",
    "        word_embeddings[idx] = word2vec[word]\n",
    "\n",
    "    word_embeddings = torch.tensor(word_embeddings, dtype=torch.float32)\n",
    "    return word2idx, word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, word_embeddings = create_word2idx_and_embeddings(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literal_eval(df.iloc[0]['neg'])[0] == 'Nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_target(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(0, len(data)):\n",
    "        title = literal_eval(data.iloc[i]['title'])\n",
    "        if  len(title) > 0 and title[0] == 'Nan':\n",
    "            title = []\n",
    "            \n",
    "        pos = literal_eval(data.iloc[i]['pos'])\n",
    "        if len(pos) > 0 and pos[0] == 'Nan':\n",
    "            pos = []\n",
    "\n",
    "\n",
    "        neg = literal_eval(data.iloc[i]['neg'])\n",
    "        if len(neg) > 0 and neg[0] == 'Nan':\n",
    "            neg = []\n",
    "\n",
    "\n",
    "        \n",
    "        x = title + pos + neg\n",
    "        if len(x) == 0:\n",
    "            continue\n",
    "            \n",
    "        X.append(x)\n",
    "        \n",
    "        y.append(data.iloc[i]['rate'] + 1)\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>bestRating</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>['Все']</td>\n",
       "      <td>['Все']</td>\n",
       "      <td>['Nan']</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>['Дуже', 'привітний', 'власник']</td>\n",
       "      <td>['Дуже', 'привітний', 'власник', 'Можна', 'бут...</td>\n",
       "      <td>['Nan']</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>['Уважний', 'та', 'приємний', 'господар']</td>\n",
       "      <td>['Уважний', 'та', 'приємний', 'господар', 'Зру...</td>\n",
       "      <td>['Nan']</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>['Буду', 'рекомендувати', 'ці', 'апартаменти',...</td>\n",
       "      <td>['Сподобалось', 'розміщення', 'чистота', 'номе...</td>\n",
       "      <td>['Нема', 'зауважень']</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>['Хороша', 'квартира', 'не', 'дуже', 'приємний...</td>\n",
       "      <td>['Хороший', 'ремонт', 'красивий', 'вид', 'з', ...</td>\n",
       "      <td>['Були', 'проблеми', 'з', 'заселенням', 'Госпо...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "5           5                                            ['Все']   \n",
       "6           6                   ['Дуже', 'привітний', 'власник']   \n",
       "7           7          ['Уважний', 'та', 'приємний', 'господар']   \n",
       "8           8  ['Буду', 'рекомендувати', 'ці', 'апартаменти',...   \n",
       "9           9  ['Хороша', 'квартира', 'не', 'дуже', 'приємний...   \n",
       "\n",
       "                                                 pos  \\\n",
       "5                                            ['Все']   \n",
       "6  ['Дуже', 'привітний', 'власник', 'Можна', 'бут...   \n",
       "7  ['Уважний', 'та', 'приємний', 'господар', 'Зру...   \n",
       "8  ['Сподобалось', 'розміщення', 'чистота', 'номе...   \n",
       "9  ['Хороший', 'ремонт', 'красивий', 'вид', 'з', ...   \n",
       "\n",
       "                                                 neg  ratingValue  bestRating  \\\n",
       "5                                            ['Nan']         10.0        10.0   \n",
       "6                                            ['Nan']          9.2        10.0   \n",
       "7                                            ['Nan']         10.0        10.0   \n",
       "8                              ['Нема', 'зауважень']         10.0        10.0   \n",
       "9  ['Були', 'проблеми', 'з', 'заселенням', 'Госпо...          8.8        10.0   \n",
       "\n",
       "   rate  \n",
       "5     1  \n",
       "6     1  \n",
       "7     1  \n",
       "8     1  \n",
       "9     0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_features_and_target(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_idxs(seq, mapping):    \n",
    "    outs_seq = []\n",
    "    for el in seq:\n",
    "        if el in mapping:\n",
    "            outs_seq.append(torch.tensor(mapping[el], dtype=torch.long))\n",
    "    outs_seq = torch.stack(outs_seq, 0)\n",
    "    return outs_seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([168077,     14,  17873,   4318, 168077,     14,  17873,   4318,  25320,\n",
       "         11908,    304,  36298,   2091, 115031,    364,   8524,   1708,      4,\n",
       "          3879,      1,   3417,   1557,   3443,  39801,  21722,  19767,   2710,\n",
       "        103133,  21526,    110,  37735,  90110,  19697, 207722,    233,    969,\n",
       "          1030])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_to_idxs(X[0], word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ідеально',\n",
       " 'для',\n",
       " 'ділової',\n",
       " 'поїздки',\n",
       " 'Ідеально',\n",
       " 'для',\n",
       " 'ділової',\n",
       " 'поїздки',\n",
       " 'Господар',\n",
       " 'зустрів',\n",
       " 'о',\n",
       " 'шостій',\n",
       " 'ранку',\n",
       " 'привітний',\n",
       " '22',\n",
       " 'поверх',\n",
       " 'вид',\n",
       " 'з',\n",
       " 'вікна',\n",
       " 'на',\n",
       " 'море',\n",
       " 'Все',\n",
       " 'поряд',\n",
       " 'супермаркет',\n",
       " 'розваги',\n",
       " 'ресторани',\n",
       " 'Було',\n",
       " 'пізнє',\n",
       " 'виселення',\n",
       " 'без',\n",
       " 'доплати',\n",
       " 'Обов',\n",
       " 'язково',\n",
       " 'зупинюся',\n",
       " 'тут',\n",
       " 'наступного',\n",
       " 'разу']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = X[0]\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([168077,     14,  17873,   4318, 168077,     14,  17873,   4318,  25320,\n",
       "          11908,    304,  36298,   2091, 115031,    364,   8524,   1708,      4,\n",
       "           3879,      1,   3417,   1557,   3443,  39801,  21722,  19767,   2710,\n",
       "         103133,  21526,    110,  37735,  90110,  19697, 207722,    233,    969,\n",
       "           1030]),\n",
       " tensor([292605,   6225,   2413,      4,   3143, 100935, 292605,   6225,   2413,\n",
       "              4,   3143, 100935,  64468,  52530,      4,   3879,    611,    346,\n",
       "         127045,   5995,      8,    438,   9561,  16947,    168, 275763,  31865,\n",
       "             33,   6693,    304,    148,   2091,      1,      5,   1042,    887,\n",
       "              9,   3673,     42,     67,      5,    174,    169,     54, 317296,\n",
       "              6,  16595,  19896,     96,     80,   1964,   9484,  12687,    374,\n",
       "             10,     16,    186,    304, 283193,  38665,  10455,     80,     54,\n",
       "             45,  31586,      3,  44386,   9913,      5,    895,  60320,    453,\n",
       "            118,      9,    169,   1230,     55,     78,    346,  85315,   2217,\n",
       "            166,    374,      6,   2184,    453,     54,      2,  14426,   4061,\n",
       "           4383,     14,   3447,  14683])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_batch = [seq_to_idxs(seq, word2idx) for seq in X[:2]]\n",
    "inputs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  tensor([292605,   6225,   2413,      4,   3143, 100935, 292605,   6225,   2413,\n",
       "               4,   3143, 100935,  64468,  52530,      4,   3879,    611,    346,\n",
       "          127045,   5995,      8,    438,   9561,  16947,    168, 275763,  31865,\n",
       "              33,   6693,    304,    148,   2091,      1,      5,   1042,    887,\n",
       "               9,   3673,     42,     67,      5,    174,    169,     54, 317296,\n",
       "               6,  16595,  19896,     96,     80,   1964,   9484,  12687,    374,\n",
       "              10,     16,    186,    304, 283193,  38665,  10455,     80,     54,\n",
       "              45,  31586,      3,  44386,   9913,      5,    895,  60320,    453,\n",
       "             118,      9,    169,   1230,     55,     78,    346,  85315,   2217,\n",
       "             166,    374,      6,   2184,    453,     54,      2,  14426,   4061,\n",
       "            4383,     14,   3447,  14683])),\n",
       " (0,\n",
       "  tensor([168077,     14,  17873,   4318, 168077,     14,  17873,   4318,  25320,\n",
       "           11908,    304,  36298,   2091, 115031,    364,   8524,   1708,      4,\n",
       "            3879,      1,   3417,   1557,   3443,  39801,  21722,  19767,   2710,\n",
       "          103133,  21526,    110,  37735,  90110,  19697, 207722,    233,    969,\n",
       "            1030]))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = sorted(enumerate(inputs_batch), key=lambda x: len(x[1]), reverse=True)\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([292605,   6225,   2413,      4,   3143, 100935, 292605,   6225,   2413,\n",
       "              4,   3143, 100935,  64468,  52530,      4,   3879,    611,    346,\n",
       "         127045,   5995,      8,    438,   9561,  16947,    168, 275763,  31865,\n",
       "             33,   6693,    304,    148,   2091,      1,      5,   1042,    887,\n",
       "              9,   3673,     42,     67,      5,    174,    169,     54, 317296,\n",
       "              6,  16595,  19896,     96,     80,   1964,   9484,  12687,    374,\n",
       "             10,     16,    186,    304, 283193,  38665,  10455,     80,     54,\n",
       "             45,  31586,      3,  44386,   9913,      5,    895,  60320,    453,\n",
       "            118,      9,    169,   1230,     55,     78,    346,  85315,   2217,\n",
       "            166,    374,      6,   2184,    453,     54,      2,  14426,   4061,\n",
       "           4383,     14,   3447,  14683]),\n",
       " tensor([168077,     14,  17873,   4318, 168077,     14,  17873,   4318,  25320,\n",
       "          11908,    304,  36298,   2091, 115031,    364,   8524,   1708,      4,\n",
       "           3879,      1,   3417,   1557,   3443,  39801,  21722,  19767,   2710,\n",
       "         103133,  21526,    110,  37735,  90110,  19697, 207722,    233,    969,\n",
       "           1030])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_batch = [inputs_batch[order_[0]] for order_ in order]\n",
    "inputs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_batch = torch.tensor([y[:2][order_[0]] for order_ in order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([292605, 168077,   6225,     14,   2413,  17873,      4,   4318,   3143,\n",
       "        168077, 100935,     14, 292605,  17873,   6225,   4318,   2413,  25320,\n",
       "             4,  11908,   3143,    304, 100935,  36298,  64468,   2091,  52530,\n",
       "        115031,      4,    364,   3879,   8524,    611,   1708,    346,      4,\n",
       "        127045,   3879,   5995,      1,      8,   3417,    438,   1557,   9561,\n",
       "          3443,  16947,  39801,    168,  21722, 275763,  19767,  31865,   2710,\n",
       "            33, 103133,   6693,  21526,    304,    110,    148,  37735,   2091,\n",
       "         90110,      1,  19697,      5, 207722,   1042,    233,    887,    969,\n",
       "             9,   1030,   3673,     42,     67,      5,    174,    169,     54,\n",
       "        317296,      6,  16595,  19896,     96,     80,   1964,   9484,  12687,\n",
       "           374,     10,     16,    186,    304, 283193,  38665,  10455,     80,\n",
       "            54,     45,  31586,      3,  44386,   9913,      5,    895,  60320,\n",
       "           453,    118,      9,    169,   1230,     55,     78,    346,  85315,\n",
       "          2217,    166,    374,      6,   2184,    453,     54,      2,  14426,\n",
       "          4061,   4383,     14,   3447,  14683]), batch_sizes=tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_packed = rnn.pack_sequence(inputs_batch)\n",
    "inputs_packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([292605, 168077,   6225,     14,   2413,  17873,      4,   4318,   3143,\n",
       "        168077, 100935,     14, 292605,  17873,   6225,   4318,   2413,  25320,\n",
       "             4,  11908,   3143,    304, 100935,  36298,  64468,   2091,  52530,\n",
       "        115031,      4,    364,   3879,   8524,    611,   1708,    346,      4,\n",
       "        127045,   3879,   5995,      1,      8,   3417,    438,   1557,   9561,\n",
       "          3443,  16947,  39801,    168,  21722, 275763,  19767,  31865,   2710,\n",
       "            33, 103133,   6693,  21526,    304,    110,    148,  37735,   2091,\n",
       "         90110,      1,  19697,      5, 207722,   1042,    233,    887,    969,\n",
       "             9,   1030,   3673,     42,     67,      5,    174,    169,     54,\n",
       "        317296,      6,  16595,  19896,     96,     80,   1964,   9484,  12687,\n",
       "           374,     10,     16,    186,    304, 283193,  38665,  10455,     80,\n",
       "            54,     45,  31586,      3,  44386,   9913,      5,    895,  60320,\n",
       "           453,    118,      9,    169,   1230,     55,     78,    346,  85315,\n",
       "          2217,    166,    374,      6,   2184,    453,     54,      2,  14426,\n",
       "          4061,   4383,     14,   3447,  14683])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_packed.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings1 = nn.Embedding.from_pretrained(word_embeddings, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = rnn.PackedSequence(word_embeddings1(inputs_packed.data), inputs_packed.batch_sizes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.4800,  0.0810,  0.2980,  ..., -0.2726, -0.0319,  0.1398],\n",
       "        [ 0.3919, -0.3237, -0.4925,  ...,  0.4331, -0.0101, -0.3867],\n",
       "        [-1.0846,  1.0709, -0.2157,  ...,  0.7148, -0.4288,  0.4748],\n",
       "        ...,\n",
       "        [-1.0628,  0.9156,  3.7243,  ..., -0.3702,  0.3234,  1.7743],\n",
       "        [-0.2340, -2.3419,  1.9534,  ..., -0.5497,  1.0787, -1.0878],\n",
       "        [ 0.4855, -0.9194,  0.5627,  ..., -0.7201,  0.9286, -0.1993]]), batch_sizes=tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_batch = [seq_to_idxs(seq, word2idx) for seq in x_batch]\n",
    "\n",
    "order = sorted(enumerate(inputs_batch), key=lambda x: len(x[1]), reverse=True)\n",
    "inputs_batch = [inputs_batch[order_[0]] for order_ in order]\n",
    "targets_batch = torch.tensor([y_batch[order_[0]] for order_ in order])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        embedding_dim -- 300\n",
    "        hidden_dim -- hidden state dimensionality\n",
    "        vocab_size -- vocabulary size\n",
    "        num_classes -- number of classes\n",
    "        pretrained_embeddings -- None or [vocab_size, embedding_dim] tensor\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, num_classes,\n",
    "                 num_layers=2,\n",
    "                 pretrained_embeddings=None, device='cpu'):\n",
    "\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.word_embeddings = nn.Embedding.from_pretrained(pretrained_embeddings,\n",
    "                                                                freeze=True).to(device)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim//2,\n",
    "                            num_layers=self.num_layers,\n",
    "                            bidirectional=True, batch_first=True)\n",
    "        self.cls = nn.Linear(hidden_dim*self.num_layers, self.num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.device = device\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = rnn.PackedSequence(self.word_embeddings(inputs.data), inputs.batch_sizes)\n",
    "        h0 = torch.randn(2*self.num_layers, inputs.batch_sizes[0], self.hidden_dim//2).to(self.device)\n",
    "        c0 = torch.randn(2*self.num_layers, inputs.batch_sizes[0], self.hidden_dim//2).to(self.device)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embeds, (h0, c0))\n",
    "        hidden = hidden.permute(1,0,2).contiguous().view(inputs.batch_sizes[0], -1)\n",
    "        scores = F.log_softmax(self.cls(self.dropout(hidden)), dim=1)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, loss_fn, optimizer, word_to_idx, device='cpu'):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.device = device\n",
    "        \n",
    "    \n",
    "    def fit(self, num_epochs, \n",
    "            X_train, y_train, train_batch_size, \n",
    "            X_val, y_val, val_batch_size, \n",
    "            log_interval=50):\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            self.__train(epoch, X_train, y_train, train_batch_size, log_interval)\n",
    "            self.__validate(epoch, X_val, y_val, val_batch_size)\n",
    "            \n",
    "            \n",
    "    def __train(self, epoch, X, y, batch_size, log_interval=5):\n",
    "        batch_start = 0\n",
    "        batch_idx = 0\n",
    "        while batch_start < len(X):\n",
    "            start = time.time()\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            X_batch = X[batch_start:batch_start + batch_size]\n",
    "            y_batch = y[batch_start:batch_start + batch_size]\n",
    "            \n",
    "            inputs_packed, targets_batch = self.__create_batch(X_batch, y_batch)\n",
    "            inputs_packed = inputs_packed.to(self.device)\n",
    "            targets_batch = targets_batch.to(self.device)\n",
    "            outputs = self.model(inputs_packed)\n",
    "\n",
    "            loss = self.loss_fn(outputs, targets_batch)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            exec_time = time.time() - start\n",
    "\n",
    "            batch_start += batch_size\n",
    "            batch_idx += 1\n",
    "            \n",
    "            if batch_idx % log_interval == 0:\n",
    "                print(f\"Train Epoch: {epoch} {min(batch_start, len(X))}/{len(X)}. Loss: {loss.item()}. Time: {exec_time} s\")        \n",
    "                \n",
    "    def __validate(self, epoch, X, y, batch_size):\n",
    "        with torch.no_grad():\n",
    "            batch_start = 0\n",
    "            batch_idx = 0\n",
    "            start = time.time()\n",
    "            while batch_start < len(X):\n",
    "                \n",
    "\n",
    "                X_batch = X[batch_start:batch_start + batch_size]\n",
    "                y_batch = y[batch_start:batch_start + batch_size]\n",
    "\n",
    "                inputs_packed, targets_batch = self.__create_batch(X_batch, y_batch)\n",
    "                \n",
    "                inputs_packed = inputs_packed.to(self.device)\n",
    "                targets_batch = targets_batch.to(self.device)\n",
    "                outputs = self.model(inputs_packed)\n",
    "                \n",
    "                loss = self.loss_fn(outputs, targets_batch)\n",
    "                F1 = self.__calc_F1_score_avg(outputs, targets_batch)\n",
    "\n",
    "                batch_start += batch_size\n",
    "                batch_idx += 1\n",
    "        \n",
    "        exec_time = time.time() - start\n",
    "        print(f\"=====> Validation. Epoch: {epoch}. Loss: {loss.item()}, F-1 score: {F1}. Time: {exec_time} s\")\n",
    "        \n",
    "    \n",
    "    def test(self, X_test, y_test, target_names):\n",
    "        with torch.no_grad():\n",
    "            inputs_packed, targets_batch = self.__create_batch(X_test, y_test)\n",
    "            inputs_packed = inputs_packed.to(self.device)\n",
    "            targets_batch = targets_batch.to(self.device)\n",
    "            outputs = self.model(inputs_packed)\n",
    "            \n",
    "            y_pred = outputs.max(dim=1)[1]\n",
    "            \n",
    "        return classification_report(targets_batch, y_pred, target_names=target_names)\n",
    "        \n",
    "                \n",
    "    \n",
    "    def __seq_to_idxs(self, seq, mapping):    \n",
    "        outs_seq = []\n",
    "        for el in seq:\n",
    "            if el in mapping:\n",
    "                outs_seq.append(torch.tensor(mapping[el], dtype=torch.long))\n",
    "        outs_seq = torch.stack(outs_seq, 0)\n",
    "        return outs_seq\n",
    "    \n",
    "    def __create_batch(self, x_batch, y_batch):\n",
    "        inputs_batch = [seq_to_idxs(seq, word2idx) for seq in x_batch]\n",
    "\n",
    "        order = sorted(enumerate(inputs_batch), key=lambda x: len(x[1]), reverse=True)\n",
    "        inputs_batch = [inputs_batch[order_[0]] for order_ in order]\n",
    "        targets_batch = torch.tensor([y_batch[order_[0]] for order_ in order])\n",
    "\n",
    "\n",
    "        inputs_packed = rnn.pack_sequence(inputs_batch)\n",
    "\n",
    "        return inputs_packed, targets_batch\n",
    "    \n",
    "    def __calc_F1_score_avg(self, outputs, targets):\n",
    "        pred = outputs.max(dim=1)[1]\n",
    "        F1 = f1_score(pred, targets, average='weighted')\n",
    "        return F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "learning_rate = 0.01\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "num_classes = 3\n",
    "device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n",
    "\n",
    "model = LSTMClassifier(embedding_dim=word_embeddings.shape[1],\n",
    "                       hidden_dim=hidden_dim,\n",
    "                       vocab_size=vocab_size,\n",
    "                       num_classes=num_classes,\n",
    "                       pretrained_embeddings=word_embeddings,\n",
    "                       device=device)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_batch_size = 16\n",
    "val_batch_size = 16\n",
    "\n",
    "trainer = Trainer(model, loss_function, optimizer, word2idx, device=device)\n",
    "trainer.fit(20, X_train, y_train, train_batch_size, X_val, y_val, val_batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = trainer.test(X_test, y_test, ['neg', 'neutral', 'pos'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
