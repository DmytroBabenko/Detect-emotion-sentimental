{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import copy\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Crowler/booking_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pos_text</th>\n",
       "      <th>neg_text</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>bestRating</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–Ω–∞—Å—Ç—É–ø–Ω–æ—ó –º–∞–Ω–¥—Ä—ñ–≤–∫–∏ –¥–æ –õ—å–≤–æ–≤–∞ –æ–±–µ—Ä–µ–º–æ —Ü–µ–π –≥–æ—Ç–µ–ª—å.</td>\n",
       "      <td>–í—ñ–¥–º—ñ–Ω–Ω–µ —Ä–æ–∑—Ç–∞—à—É–≤–∞–Ω–Ω—è –≥–æ—Ç–µ–ª—é! –î—É–∂–µ –±–ª–∏–∑—å–∫–æ –¥–æ ...</td>\n",
       "      <td>–æ–¥–∏–Ω –º–∞–ª–µ–Ω—å–∫–∏–π –º—ñ–Ω—É—Å, –∞–ª–µ –Ω–∞–º —Ü–µ –Ω–µ –∑–∞–≤–¥–∞–ª–æ –Ω–µ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–°–Ω—ñ–¥–∞–Ω–æ–∫ - –≤–µ–ª–∏–∫—ñ –ø–æ—Ä—Ü—ñ—ó—ó, —Å–º–∞—á–Ω–æ!</td>\n",
       "      <td>–°–Ω—ñ–¥–∞–Ω–æ–∫ - –≤–µ–ª–∏–∫—ñ –ø–æ—Ä—Ü—ñ—ó—ó, —Å–º–∞—á–Ω–æ! 1 —Å—Ç—Ä–∞–≤–∞ –±–µ...</td>\n",
       "      <td>–°–∞–º –≥–æ—Ç–µ–ª—å —É—Å–µ—Ä–µ–¥–∏–Ω—ñ –Ω–∞–≥–∞–¥—É—î –≥—É—Ä—Ç–æ–∂–∏—Ç–æ–∫ —á–∏ —Ö–æ—Å...</td>\n",
       "      <td>6.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–í—Å–µ —á—É–¥–æ–≤–æ! –ó–∞ –Ω–∞–≥–æ–¥–∏, –æ–±–æ–≤'—è–∑–∫–æ–≤–æ –∑–Ω–æ–≤—É –∑–∞–≤—ñ—Ç...</td>\n",
       "      <td>–î—É–∂–µ —á—É–¥–æ–≤–∏–π —ñ –∑–∞—Ç–∏—à–Ω–∏–π –æ—Ç–µ–ª—å! –î—É–∂–µ –∑—Ä—É—á–Ω–µ —Ä–æ–∑...</td>\n",
       "      <td>–°–∞–Ω—Ç–µ—Ö–Ω—ñ–∫—É (—Ç—Ä—É–±–∏ , —Å—Ç–æ–∫–∏) –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç...</td>\n",
       "      <td>9.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–∫–ª–∞—Å–Ω–µ —Ä–æ–∑—Ç–∞—à—É–≤–∞–Ω–Ω—è, —Ç–∞–∫–∏–π —Å–æ–±—ñ –æ—Å—Ç—Ä—ñ–≤–µ—Ü—å —Ç–∏—à—ñ...</td>\n",
       "      <td>–∫–ª–∞—Å–Ω–µ —Ä–æ–∑—Ç–∞—à—É–≤–∞–Ω–Ω—è, —Ç–∞–∫–∏–π —Å–æ–±—ñ –æ—Å—Ç—Ä—ñ–≤–µ—Ü—å —Ç–∏—à—ñ...</td>\n",
       "      <td>–Ω–∞—á–µ–±—Ç–æ –Ω–æ–≤–∏–π —Ä–µ–º–æ–Ω—Ç - –∞ –≤–µ–ª–∏–∫–∞ —Ç—Ä—ñ—â–∏–Ω–∞ –Ω–∞–¥ –¥–≤...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ì–∞—Ä–Ω–µ –º—ñ—Å—Ü–µ –¥–ª—è —Ç—É—Ä–∏—Å—Ç—ñ–≤ –∞–±–æ –≤—ñ–¥—Ä—è–¥–∂–µ–Ω–Ω—è, –∞–ª–µ ...</td>\n",
       "      <td>–Ü–¥–µ–∞–ª—å–Ω–∏–π –Ω–æ–º–µ—Ä, —è–∫ –¥–ª—è —Ç—Ä–∏–∑—ñ—Ä–∫–æ–≤–æ–≥–æ –≥–æ—Ç–µ–ª—é - ...</td>\n",
       "      <td>–î—É–∂–µ –∫—Ä—É—Ç—ñ —Å—Ö–æ–¥–∏. –°–∫–ª–∞–¥–Ω–æ –∑–Ω–∞–π—Ç–∏ –ø–æ—Ä—É—á –º—ñ—Å—Ü–µ –¥...</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  –Ω–∞—Å—Ç—É–ø–Ω–æ—ó –º–∞–Ω–¥—Ä—ñ–≤–∫–∏ –¥–æ –õ—å–≤–æ–≤–∞ –æ–±–µ—Ä–µ–º–æ —Ü–µ–π –≥–æ—Ç–µ–ª—å.   \n",
       "1                 –°–Ω—ñ–¥–∞–Ω–æ–∫ - –≤–µ–ª–∏–∫—ñ –ø–æ—Ä—Ü—ñ—ó—ó, —Å–º–∞—á–Ω–æ!   \n",
       "2  –í—Å–µ —á—É–¥–æ–≤–æ! –ó–∞ –Ω–∞–≥–æ–¥–∏, –æ–±–æ–≤'—è–∑–∫–æ–≤–æ –∑–Ω–æ–≤—É –∑–∞–≤—ñ—Ç...   \n",
       "3  –∫–ª–∞—Å–Ω–µ —Ä–æ–∑—Ç–∞—à—É–≤–∞–Ω–Ω—è, —Ç–∞–∫–∏–π —Å–æ–±—ñ –æ—Å—Ç—Ä—ñ–≤–µ—Ü—å —Ç–∏—à—ñ...   \n",
       "4  –ì–∞—Ä–Ω–µ –º—ñ—Å—Ü–µ –¥–ª—è —Ç—É—Ä–∏—Å—Ç—ñ–≤ –∞–±–æ –≤—ñ–¥—Ä—è–¥–∂–µ–Ω–Ω—è, –∞–ª–µ ...   \n",
       "\n",
       "                                            pos_text  \\\n",
       "0  –í—ñ–¥–º—ñ–Ω–Ω–µ —Ä–æ–∑—Ç–∞—à—É–≤–∞–Ω–Ω—è –≥–æ—Ç–µ–ª—é! –î—É–∂–µ –±–ª–∏–∑—å–∫–æ –¥–æ ...   \n",
       "1  –°–Ω—ñ–¥–∞–Ω–æ–∫ - –≤–µ–ª–∏–∫—ñ –ø–æ—Ä—Ü—ñ—ó—ó, —Å–º–∞—á–Ω–æ! 1 —Å—Ç—Ä–∞–≤–∞ –±–µ...   \n",
       "2  –î—É–∂–µ —á—É–¥–æ–≤–∏–π —ñ –∑–∞—Ç–∏—à–Ω–∏–π –æ—Ç–µ–ª—å! –î—É–∂–µ –∑—Ä—É—á–Ω–µ —Ä–æ–∑...   \n",
       "3  –∫–ª–∞—Å–Ω–µ —Ä–æ–∑—Ç–∞—à—É–≤–∞–Ω–Ω—è, —Ç–∞–∫–∏–π —Å–æ–±—ñ –æ—Å—Ç—Ä—ñ–≤–µ—Ü—å —Ç–∏—à—ñ...   \n",
       "4  –Ü–¥–µ–∞–ª—å–Ω–∏–π –Ω–æ–º–µ—Ä, —è–∫ –¥–ª—è —Ç—Ä–∏–∑—ñ—Ä–∫–æ–≤–æ–≥–æ –≥–æ—Ç–µ–ª—é - ...   \n",
       "\n",
       "                                            neg_text  ratingValue  bestRating  \\\n",
       "0  –æ–¥–∏–Ω –º–∞–ª–µ–Ω—å–∫–∏–π –º—ñ–Ω—É—Å, –∞–ª–µ –Ω–∞–º —Ü–µ –Ω–µ –∑–∞–≤–¥–∞–ª–æ –Ω–µ...         10.0        10.0   \n",
       "1  –°–∞–º –≥–æ—Ç–µ–ª—å —É—Å–µ—Ä–µ–¥–∏–Ω—ñ –Ω–∞–≥–∞–¥—É—î –≥—É—Ä—Ç–æ–∂–∏—Ç–æ–∫ —á–∏ —Ö–æ—Å...          6.3        10.0   \n",
       "2  –°–∞–Ω—Ç–µ—Ö–Ω—ñ–∫—É (—Ç—Ä—É–±–∏ , —Å—Ç–æ–∫–∏) –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç...          9.6        10.0   \n",
       "3  –Ω–∞—á–µ–±—Ç–æ –Ω–æ–≤–∏–π —Ä–µ–º–æ–Ω—Ç - –∞ –≤–µ–ª–∏–∫–∞ —Ç—Ä—ñ—â–∏–Ω–∞ –Ω–∞–¥ –¥–≤...          7.5        10.0   \n",
       "4  –î—É–∂–µ –∫—Ä—É—Ç—ñ —Å—Ö–æ–¥–∏. –°–∫–ª–∞–¥–Ω–æ –∑–Ω–∞–π—Ç–∏ –ø–æ—Ä—É—á –º—ñ—Å—Ü–µ –¥...          9.2        10.0   \n",
       "\n",
       "   rate  \n",
       "0     1  \n",
       "1     0  \n",
       "2     1  \n",
       "3     0  \n",
       "4     1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stop_words(file):\n",
    "    with open(file) as f:\n",
    "        stop_words = f.read().split('\\n')\n",
    "\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = read_stop_words('ukrainian-stopwords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_symbols = [',', '.', '!', '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = ignore_symbols + stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_words_from_sentence_to_bag_of_words(sentence : str, ignore_words: list, bag_of_words : set):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    for word in words:\n",
    "        if word in ignore_words:\n",
    "            continue\n",
    "        bag_of_words.add(stemmer.stem(word.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = set()\n",
    "for i in range(0, len(data)):\n",
    "    add_words_from_sentence_to_bag_of_words(data['title'][i], ignore, bag_of_words)\n",
    "    add_words_from_sentence_to_bag_of_words(data['pos_text'][i], ignore, bag_of_words)\n",
    "    add_words_from_sentence_to_bag_of_words(data['neg_text'][i], ignore, bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bag_of_words_vector(sentence: str, ignore_words : list, bag_of_words : set):\n",
    "    d = dict.fromkeys(bag_of_words, 0) \n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    for word in words:\n",
    "        if word in d:\n",
    "            d[word] += 1\n",
    "            \n",
    "    return list(d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words_dict = {}\n",
    "for word in bag_of_words:\n",
    "    bag_of_words_dict[word] = len(data) * [0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag_of_words_dict = dict.fromkeys(bag_of_words, copy.copy(zeros)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_item_to_bag_of_words_dict(sentence: str, ignore_words : list, index, bag_of_words_dict : dict):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    for word in words:\n",
    "        if word in bag_of_words_dict:\n",
    "            bag_of_words_dict[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for i in range(0, len(data)):\n",
    "    title = create_bag_of_words_vector(data['title'][i], ignore, bag_of_words)\n",
    "    pos_text = create_bag_of_words_vector(data['pos_text'][i], ignore, bag_of_words)\n",
    "    neg_text = create_bag_of_words_vector(data['neg_text'][i], ignore, bag_of_words)\n",
    "    rate_value = data['rate'][i]\n",
    "    xi = title + pos_text + neg_text\n",
    "    xi = np.array(title) + np.array(pos_text) + np.array(neg_text)\n",
    "    yi = rate_value\n",
    "    \n",
    "    X.append(xi)\n",
    "    y.append(yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in range(0, len(data)):\n",
    "    add_item_to_bag_of_words_dict(data['title'][i], ignore, i, bag_of_words_dict)\n",
    "    add_item_to_bag_of_words_dict(data['pos_text'][i], ignore, i, bag_of_words_dict)\n",
    "    add_item_to_bag_of_words_dict(data['neg_text'][i], ignore, i, bag_of_words_dict)\n",
    "\n",
    "    rate_value = data['rate'][i]\n",
    "    yi = rate_value\n",
    "    \n",
    "    y.append(yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(bag_of_words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>—Ä–µ—à—Ç</th>\n",
       "      <th>—Å–º–µ—à–Ω—ã–µ</th>\n",
       "      <th>–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä</th>\n",
       "      <th>–ø–æ—Å–ª–∏–∑–Ω—É—Ç–∏—Å—è</th>\n",
       "      <th>–ª–æ–∫–∞—Ü—ñ—èÔºÅ</th>\n",
       "      <th>–Ω–µ–∫–æ–º—Ñ–æ—Ä—Ç–Ω—ñ—Å—Ç—å</th>\n",
       "      <th>–≤–∏—Å–æ–∫–∞</th>\n",
       "      <th>—â—ñ—Ç–æ–∫</th>\n",
       "      <th>–≤–µ–ª–∏–∫–æ—é</th>\n",
       "      <th>–ø—Ä–æ—Å–æ—á—É–≤–∞–ª–∞—Å—å</th>\n",
       "      <th>...</th>\n",
       "      <th>–æ–¥–Ω–∞–∫–æ–≤–∏–π</th>\n",
       "      <th>—Ç—É—Ç</th>\n",
       "      <th>–∫–ª—ñ—Ç–∫–∏</th>\n",
       "      <th>–∑–∞—Å–æ–±–æ–º</th>\n",
       "      <th>—Ä—É—Ö—É</th>\n",
       "      <th>–ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è</th>\n",
       "      <th>—á—É–ª–∞</th>\n",
       "      <th>–ø—É—Å—Ç–∏–π</th>\n",
       "      <th>–ø—Ä–∏–µ—Ö–∞–ª</th>\n",
       "      <th>–≤–∏—è—Å–Ω–∏—Ç–∏</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 8770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   —Ä–µ—à—Ç  —Å–º–µ—à–Ω—ã–µ  –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä  –ø–æ—Å–ª–∏–∑–Ω—É—Ç–∏—Å—è  –ª–æ–∫–∞—Ü—ñ—èÔºÅ  –Ω–µ–∫–æ–º—Ñ–æ—Ä—Ç–Ω—ñ—Å—Ç—å  –≤–∏—Å–æ–∫–∞  \\\n",
       "0     0        0            0             0         0               0       0   \n",
       "1     0        0            0             0         0               0       0   \n",
       "2     0        0            0             0         0               0       0   \n",
       "3     0        0            0             0         0               0       0   \n",
       "4     0        0            0             0         0               0       0   \n",
       "\n",
       "   —â—ñ—Ç–æ–∫  –≤–µ–ª–∏–∫–æ—é  –ø—Ä–æ—Å–æ—á—É–≤–∞–ª–∞—Å—å  ...  –æ–¥–Ω–∞–∫–æ–≤–∏–π  —Ç—É—Ç  –∫–ª—ñ—Ç–∫–∏  –∑–∞—Å–æ–±–æ–º  —Ä—É—Ö—É  \\\n",
       "0      0        0              0  ...          0    0       0        0     0   \n",
       "1      0        0              0  ...          0    0       0        0     0   \n",
       "2      0        0              0  ...          0    0       0        0     0   \n",
       "3      0        0              0  ...          0    0       0        0     0   \n",
       "4      0        0              0  ...          0    0       0        0     0   \n",
       "\n",
       "   –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è  —á—É–ª–∞  –ø—É—Å—Ç–∏–π  –ø—Ä–∏–µ—Ö–∞–ª  –≤–∏—è—Å–Ω–∏—Ç–∏  \n",
       "0             0     0       0        0         0  \n",
       "1             0     0       0        0         0  \n",
       "2             0     0       0        0         0  \n",
       "3             0     0       0        0         0  \n",
       "4             0     0       0        0         0  \n",
       "\n",
       "[5 rows x 8770 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42, solver='lbfgs', multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "825"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.16      0.24        19\n",
      "           0       0.56      0.58      0.57        77\n",
      "           1       0.65      0.70      0.68       111\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       207\n",
      "   macro avg       0.57      0.48      0.49       207\n",
      "weighted avg       0.60      0.61      0.60       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8770"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of some specific words in all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_num_of_word_occurrences(word):\n",
    "    print(f\"{word} - {sum(bag_of_words_dict[word])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—à–∏–∫–∞—Ä–Ω–µ - 1\n",
      "–ø–æ–≤–µ—Ä—Ö–Ω—é - 1\n",
      "üòÅüòâ - 1\n"
     ]
    }
   ],
   "source": [
    "print_num_of_word_occurrences(\"—à–∏–∫–∞—Ä–Ω–µ\")\n",
    "print_num_of_word_occurrences(\"–ø–æ–≤–µ—Ä—Ö–Ω—é\")\n",
    "print_num_of_word_occurrences(\"üòÅüòâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,\n",
    "                                                   mode = 'classification',\n",
    "                                                   feature_names = X_train.columns,\n",
    "                                                   categorical_features = [], \n",
    "                                                   categorical_names = [], \n",
    "                                                   discretize_continuous = True)\n",
    "                                                   \n",
    "np.random.seed(42)\n",
    "exp = explainer.explain_instance(X_train.values[31], clf.predict_proba, num_features = len(X_train.columns))\n",
    "exp.show_in_notebook(show_all=False) #only the features used in the explanation are displayed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bag_of_words_dict['–±–æ–ª–∏—Ç—å'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bag_of_words_dict['–≥–æ—Ç–µ–ª—å'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
